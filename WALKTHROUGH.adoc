= Opendaylight integration with OpenNMS
:imagesdir: assets/images

As a user and developer of OpenNMS I've often wanted to be able to use and test the platform's features in a controlled environment.
The challenge continues to be setting up a network and services in such a way that can be used to drive the solution.

Here we leverage the Opendaylight integration in OpenNMS to create a virtual network that can be used to exercise and test the platform.

It can be used to help you:

* Interact with alarms
* Interact with topology
* Interact with performance data
* Interact with correlation
* Interact with flows
* Develop using the OIA

This document will walk you through setting up the Opendaylight integration and use it to show case some of the features available in OpenNMS.

== Setting up OpenNMS

This walkthrough assumes that you have an existing instance of OpenNMS Horizon 29.0.0 or greater running.

== Setup the network

Fire up OpenDaylight:
```
mkdir -p /tmp/sdn/odl
cd /tmp/sdn
wget https://nexus.opendaylight.org/content/repositories/public/org/opendaylight/integration/karaf/0.8.4/karaf-0.8.4.tar.gz
tar zxvf karaf-0.8.4.tar.gz -C odl --strip-components=1
./odl/bin/karaf
```

IMPORTANT: When running both OpenNMS and OpenDaylight on the same host you'll need to A) disable the `PollerBackEnd` service in OpenNMS (RMI port conflict) and B) change the SSH port for one of the containers in `org.apache.karaf.shell.cfg` (SSH port conflict).

Install the following features:
```
feature:install odl-mdsal-all odl-restconf odl-l2switch-switch
```

Fire up Containernet:
```
docker pull containernet/containernet:v1
docker run --name containernet -it -d --privileged --pid='host' -v /var/run/docker.sock:/var/run/docker.sock containernet/containernet:v1           
docker exec -it containernet /bin/bash
```

Make sure you can connect back to your SDN controller from the containernet shell:
```
export OPENDAYLIGHT_HOST=172.17.0.1
export OPENDAYLIGHT_PORT=6633
telnet $OPENDAYLIGHT_HOST $OPENDAYLIGHT_PORT
```

Use a script that connects to a remote controller:
```
cat >net.py <<EOT
#!/usr/bin/python
from mininet.net import Mininet
from mininet.node import Controller, RemoteController
from mininet.topolib import TreeTopo
from mininet.cli import CLI
from mininet.link import TCLink
from mininet.log import info, setLogLevel
setLogLevel('info')

c0 = RemoteController('c0', ip='$OPENDAYLIGHT_HOST', port=$OPENDAYLIGHT_PORT)
topo = TreeTopo(depth=2, fanout=3)
net = Mininet(topo=topo, build=False)
net.addController(c0)
net.build()
net.start()
info('*** Running CLI\n')
CLI(net)
info('*** Stopping network')
net.stop()
EOT
```

Start the script:
```
chmod +x net.py
./net.py
```

NOTE: If you encounter an error of the form `Exception: Error creating interface pair (s1-eth1,s2-eth3): RTNETLINK answers: File exists`, try running `sudo mn -c` to reset.

When the shell is ready, run:
```
containernet> pingall
*** Ping: testing ping reachability
h1 -> X h3 h4 h5 h6 h7 h8 h9
h2 -> h1 h3 h4 h5 h6 h7 h8 h9
h3 -> h1 h2 h4 h5 h6 h7 h8 h9
h4 -> h1 h2 h3 h5 h6 h7 h8 h9
h5 -> h1 h2 h3 h4 h6 h7 h8 h9
h6 -> h1 h2 h3 h4 h5 h7 h8 h9
h7 -> h1 h2 h3 h4 h5 h6 h8 h9
h8 -> h1 h2 h3 h4 h5 h6 h7 h9
h9 -> h1 h2 h3 h4 h5 h6 h7 h8
*** Results: 1% dropped (71/72 received)
```

You can also display the topology using:
```
containernet> links
s1-eth1<->s2-eth4 (OK OK)
s1-eth2<->s3-eth4 (OK OK)
s1-eth3<->s4-eth4 (OK OK)
s2-eth1<->h1-eth0 (OK OK)
s2-eth2<->h2-eth0 (OK OK)
s2-eth3<->h3-eth0 (OK OK)
s3-eth1<->h4-eth0 (OK OK)
s3-eth2<->h5-eth0 (OK OK)
s3-eth3<->h6-eth0 (OK OK)
s4-eth1<->h7-eth0 (OK OK)
s4-eth2<->h8-eth0 (OK OK)
s4-eth3<->h9-eth0 (OK OK)
```

=== Enable flows

In a separate shell in the Mininet container run:
```
cat >enable_flows.sh <<EOT
COLLECTOR_IP=172.23.2.78
COLLECTOR_PORT=4730
INDEX=1
for SWITCH in "s1" "s2" "s3" "s4"
do
        ovs-vsctl -- set Bridge $SWITCH ipfix=@i -- --id=@i create IPFIX targets=\"${COLLECTOR_IP}:${COLLECTOR_PORT}\" obs_domain_id="${INDEX}"
        let INDEX=${INDEX}+1
done
EOT
```

Start the script:
```
chmod +x enable_flows.sh
./enable_flows.sh
```

TIP: Use `iperf h1 h4` in the Mininet console to generate traffic.

== Import the network

Compile the OpenDaylight plugin:
```
git clone https://github.com/OpenNMS/opennms-opendaylight-plugin
cd opennms-opendaylight-plugin
mvn clean install
```

Install the OpenDaylight plugin.
From the OpenNMS Karaf shell:
```
feature:repo-add mvn:org.opennms.plugins.odl/odl-karaf-features/1.0.0-SNAPSHOT/xml
config:edit org.opennms.plugins.opendaylight
property-set controllerUrl http://localhost:8181
config:update
feature:install opennms-plugins-odl
```

Set the log level:
```
log:set INFO org.opennms.plugins.odl
```

Verify controller communication using the `health:check` command:
```
Connect to the Opendaylight controller         [ Success  ] => Found 1 topology(s).
```

Render the requisition using:
```
opennms:show-import -x opendaylight
```

TIP: Add a foreign source with no detectors:
`curl -v -u admin:admin -X POST http://localhost:8980/opennms/rest/foreignSources \
    -H "Content-Type: application/xml" \
    --data '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><foreign-source xmlns="http://xmlns.opennms.org/xsd/config/foreign-source" name="ODL" date-stamp="2019-01-28T13:58:27.945-05:00"><scan-interval>12w</scan-interval><detectors/><policies/></foreign-source>'`

Trigger the import using:
```
opennms:import-requisition opendaylight
```

Verify that the nodes were provisioned and have started persisting metrics:
```
opennms:show-measurement-resources -n ODL:openflow_1
```

== Flows

Update `etc/telemetryd-configuration.xml`:
```
   <queue name="IPFIX">
        <adapter name="IPFIX-Adapter" class-name="org.opennms.netmgt.telemetry.protocols.netflow.adapter.ipfix.IpfixAdapter" enabled="true">
            <parameter key="metaDataNodeLookup" value="ODL:nodeIdIndex"/>
        </adapter>
    </queue>
```

== Topology

Imported inventory:

image::ovs_node.png[Open vSwitch Node,800]

Topology:

image::mininet_topology.png[Mininet topology,800]

== Alarms

Now that our inventory is provisioned, let's trigger a fault.
From the Mininet console:
```
containernet> link s2 h1 down
containernet> link s3 h4 down
```

We should see an alarm associated with node that has 'openflow:3' as the label.

image::mininet_topology_alarms.png[Topology with alarms triggered,800]

We can also take the opportunity to look at the alarms in Helm:

image::helm_alarms.png[Helm with alarms triggered,800]

== ALEC

=== Setup

Load ALEC in OpenNMS:

```
feature:repo-add mvn:org.opennms.alec/alec-karaf-features/1.0.2-SNAPSHOT/xml
feature:install alec-opennms-standalone
```


Customize the inventory mapping:

```
cp datasource/opennms-direct/src/main/resources/inventory.groovy /tmp/inventory.groovy
```

Edit `/tmp/inventory.groovy` and change the `PORT_LINK_WEIGHT` constant to `25`.

Configure the datasource to use the custom inventory mapping:

```
config:edit org.opennms.alec.datasource.opennms.direct
config:property-set scriptFile /tmp/inventory.groovy
config:update
```

Restart the driver:
```
bundle:restart org.opennms.alec.driver.main
```

Verify that everything is running again:
```
admin@opennms> opennms-alec:list-graphs 
dbscan: 1 situations on 37 vertices and 48 edges.
```

=== Situations

Now, let's trigger a few alarms on the same switch:
```
link s4 h7 down
link s4 h8 down
link s4 h9 down
```

The 3 alarms should be visible in the Topology UI:

image::mininet_topology_alarms_for_situation.png[Topology with alarms from situation,800]

The 3 alarms should be correlated into a single situation:

image::nms_situation.png[Situation in OpenNMS,800]

We can also view the situation from Helm:

image::helm_situation.png[Situation in Helm,800]

==== Feedback

Install the situation feedback feature in OpenNMS:
```
feature:install opennms-situation-feedback
```

And provide feedback from the alarm details modal in Helm:

image::helm_feedback.png[Situation feedback in Helm,800]

This feedback will be saved in Elasticsearch and can be used to help train the correlation engine's behavior.

=== Graph Visualization

Let's export the graph from ALEC:

```
feature:install alec-features-shell
opennms-alec:export-graph dbscan /tmp/alec.graphml.xml
```

And now POST it to OpenNMS:

```
curl -X POST -H "Content-Type: application/xml" -u admin:admin -d@/tmp/alec.graphml.xml 'http://localhost:8980/opennms/rest/graphml/alec'
```

We can then view the graph using the Topology UI:

image::topology_alec_graph.png[Topology with ALEC graph,800]

=== 3D Visualization

Let's take a snapshot of the state:
```
feature:install alec-features-shell
opennms-alec:datasource-snapshot /tmp/snap1
```

Load the snapshot in the ALEC visualization tool:
```
docker pull opennms/alec-viz
docker run -p 8082:8080 -v /tmp/snap1:/dataset opennms/alec-viz
```

Open browser to: http://localhost:8082/static/index.html and view the situation along with the alarms and inventory graph in 3D:

image::alec_graph_3d.png[Topology with alarms triggered,800]
